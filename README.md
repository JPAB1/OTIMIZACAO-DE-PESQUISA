# üöÄ Otimiza√ß√£o com PySpark

Este projeto demonstra como utilizar **PySpark** para leitura, manipula√ß√£o e otimiza√ß√£o de dados em formato **Parquet**, explorando conceitos como **joins**, **repartition**, **coalesce** e **explain** para an√°lise de performance.

---

## üì¶ Instala√ß√£o

Antes de executar o notebook, instale o PySpark:

```bash
pip install pyspark
```
## üìö Importa√ß√µes

O projeto utiliza os seguintes pacotes:

- **pyspark** ‚Üí Biblioteca principal para processamento distribu√≠do  
- **pyspark.sql.SparkSession** ‚Üí Cria√ß√£o da sess√£o Spark  
- **pyspark.sql.functions** ‚Üí Fun√ß√µes SQL para manipula√ß√£o de dados  
- **py4j.java_gateway** ‚Üí Comunica√ß√£o entre Python e JVM  

## ‚öôÔ∏è Etapas do Projeto

### 1. Cria√ß√£o da sess√£o Spark
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()
```

### 2. Leitura dos arquivos Parquet

Os arquivos de entrada s√£o lidos e armazenados em DataFrames:

- **videos-preparados.snappy.parquet** ‚Üí DataFrame `df_video`  
- **video-comments-tratados.snappy.parquet** ‚Üí DataFrame `df_comments`  

```python
df_video = spark.read.option("header", "true").parquet(
    'drive/MyDrive/Colab Notebooks/spark/data/material_de_apoio_m27/videos-preparados.snappy.parquet'
)

df_comments = spark.read.option("header", "true").parquet(
    'drive/MyDrive/Colab Notebooks/spark/data/material_de_apoio_m27/videos-comments-tratados.snappy.parquet'
)
```
### 3. Cria√ß√£o de tabelas tempor√°rias

As tabelas tempor√°rias s√£o criadas a partir dos DataFrames para permitir consultas SQL:

```python
df_video.createOrReplaceTempView("df_video")
df_comments.createOrReplaceTempView("df_comments")
```
### 4. Join entre v√≠deos e coment√°rios

Realizando o join entre os v√≠deos e seus respectivos coment√°rios:

```sql
SELECT v.Title, v.`Video ID`, c.Comments, c.Likes
FROM df_video v
JOIN df_comments c ON v.`Video ID` = c.`Video ID`
```
### 5. Otimiza√ß√£o com repartition e coalesce

- **repartition(n)** ‚Üí Redistribui os dados em **n** parti√ß√µes  
- **coalesce(n)** ‚Üí Reduz o n√∫mero de parti√ß√µes sem redistribui√ß√£o completa  

#### Exemplo em Python:
```python
df_video_rep = df_video.repartition(3)
df_video_rdd = df_video.coalesce(2)
```
### 6. An√°lise de plano de execu√ß√£o com explain

Permite entender como o Spark est√° processando os dados:

```python
df_video.explain()
df_video_rdd.explain()
```
### 7. Join otimizado com filtro

Filtrando apenas v√≠deos com n√∫mero de likes acima da m√©dia:

```python
media_likes = df_video.select(avg("Likes").alias('media_likes'))

join_video_comments_otimizado = df_video.join(
    media_likes,
    df_video['Likes'] > media_likes['media_likes']
).select(df_video['*'])
```
### 8. Salvando resultado em Parquet

Ap√≥s realizar o join otimizado, o resultado √© salvo em formato **Parquet** para armazenamento eficiente:

```python
join_video_comments_otimizado.write.mode("overwrite").parquet(
    'drive/MyDrive/Colab Notebooks/spark/data/join-videos-comments-otimizado_parquet'
)
```
## üìä Conceitos Importantes

- **Repartition**: aumenta ou redistribui parti√ß√µes ‚Üí √∫til para balancear carga.  
- **Coalesce**: reduz parti√ß√µes sem shuffle ‚Üí mais eficiente para diminuir parti√ß√µes.  
- **Explain**: mostra o plano l√≥gico e f√≠sico de execu√ß√£o ‚Üí essencial para otimiza√ß√£o.  
- **Join + Filter**: aplicar filtros antes ou durante o join reduz custo computacional.  

---

## üõ†Ô∏è Requisitos

- **Python 3.7+**  
- **PySpark**  
- **Google Colab** ou ambiente com suporte a Spark  
- Arquivos Parquet de entrada:  
  - `videos-preparados.snappy.parquet`  
  - `video-comments-tratados.snappy.parquet`  

## üìÇ Estrutura de Sa√≠da

Ap√≥s execu√ß√£o, ser√° gerado o arquivo:

```bash
join-videos-comments-otimizado_parquet/
```
Contendo os dados otimizados do join entre v√≠deos e coment√°rios.

## ‚úÖ Conclus√£o

Este notebook mostra como:

- **Ler e manipular dados com PySpark**  
- **Criar joins entre DataFrames**  
- **Otimizar consultas com repartition, coalesce e filtros**  
- **Analisar planos de execu√ß√£o com explain**  
- **Exportar resultados em formato Parquet**  
